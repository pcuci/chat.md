

---
You're an expert software engineer with shell and code knowledge.

Instructions:

    - You should use the provided bash execution, reading and writing file tools to complete objective.
    - First understand about the project by getting the folder structure (ignoring .git, node_modules, venv, etc.)
    - Do not provide code snippets unless asked by the user, instead directly add/edit the code.
    - Do not install new tools/packages before ensuring no such tools/package or an alternative already exists.
    - Do not use artifacts if you have access to the repository and not asked by the user to provide artifacts/snippets. Directly create/update using wcgw tools
    - Do not use Ctrl-c or interrupt commands without asking the user, because often the programs don't show any update but they still are running.
    - Do not use echo to write multi-line files, always use FileWriteOrEdit tool to update a code.
    - Provide as many file paths as you need in ReadFiles in one go.

Additional instructions:
    Always run `pwd` if you get any file or directory not found error to make sure you're not lost, or to get absolute cwd.

    Always write production ready, syntactically correct code.




# Environment
System: Darwin
Machine: arm64
Initialized in directory (also cwd): /Users/arusia/repos/filechat
User home directory: /Users/arusia

---
# Workspace structure
/Users/arusia/repos/filechat
  .vscode
    launch.json
    tasks.json
  samples
    cmdassets
      tool-result-20250331-131557-z0cpzy.txt
      tool-result-20250331-131638-21zkx4.txt
      ...
    add_newline.py
    image-1.png
    image-2.png
    image-3.png
    image-4.png
    image.png
    vite-todo-app-react.chat.md
    ...
  src
    tools
      toolExecutor.ts
    types
      mcp-fix.d.ts
    utils
      fileUtils.ts
      lock.ts
    anthropicClient.ts
    config.ts
    extension.ts
    listener.ts
    mcpClient.ts
    mcpClientManager.ts
    openaiClient.ts
    parser.ts
    streamer.ts
    types.ts
  .gitignore
  .npmignore
  .vscodeignore
  addStatusIndicator.chat.md
  anthropic-test.chat.md
  CLAUDE.md
  debug-test.chat.md
  esbuild.js
  gemini-test.chat.md
  LICENSE
  newline-test.chat.md
  no-newline-test.chat.md
  openai-test.chat.md
  package-lock.json
  package.json
  README.md
  sample-config-with-base-url.jsonc
  sample-config.jsonc
  sample.chat.md
  setup.sh
  test-tool-calling.js
  test.chat.md
  test_bug.chat.md
  tool-calling-example.chat.md
  tsconfig.json
  ...

---


---
# CLAUDE.md - Project alignment guidelines
```
I want you to plan a vscode extension.

# What is the extension about?

Any file with extension .chat.md

is used as chat interface with an LLM

# Theory

The file is a view of MessageParam data structure which is the chat conversation history with role user or assistant and content a list of text type or image type.

# States

The extension doesn't have any long term state, it only has configuration which is part of vscode settings

At any given point of time there's a listener running that listens to keystrokes, and decides to call an LLM for streaming or not.

At any given of point of time there are one or more streamers running.

A "streamer" is a thread that's streaming from LLM a set of tokens at a time.

# .chat.md parsing

# %% user
Hi
# %% assistant
hello

# %% line is treated as describing a role and starting a text block.

In user block a md like relative url is resolved for text or image file.

All text and image files are parsed as attachment of user message at the beginning of the user turn with file paths introduced in one of two formats:

1. Using the "Attached file at" syntax:
Attached file at /Users/arusia/test.ts
```
// content
```
Attached file at /Users/arusia/image.png
[image content]

2. Using Markdown-style links with #file tag:
[#file](test.py)
[#file](/absolute/path/to/image.png)

Both relative and absolute paths are supported in either format. Home directory paths using tilde (~) are also supported.

# When to trigger streaming

If the file ends with an empty assistant block # %% assistant\s* without case match the streaming starts

# How to stream idempotentically

At each loop step of the streamer there are a list of tokens received.

The history of tokens of current streamer (a single turn) is also saved in the streamer.

The past text is searched for in the last non-empty assistant block and if found the new tokens are appended regardless of presence of any subsequent text.

If no such text is found (say user deleted), the streamer should abort and cancelled. The streamer's data deleted.

# Locks

A lock on the file is shared between streamer and the listener, only is allowed to run at a time.

# Configuration

For now only anthropic is supported, and only configuration is ANTHROPIC_API_KEY


```
---


---
# Requested files

/Users/arusia/repos/filechat/package.json
```
{
  "name": "filechat",
  "displayName": "Chat Markdown",
  "description": "Interact with LLMs directly in markdown files",
  "version": "0.1.0",
  "publisher": "arusia",
  "repository": {
    "type": "git",
    "url": "https://github.com/arusia/filechat"
  },
  "engines": {
    "vscode": "^1.60.0"
  },
  "categories": [
    "Other"
  ],
  "activationEvents": [
    "onLanguage:markdown",
    "onStartupFinished"
  ],
  "main": "./dist/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "filechat.newChat",
        "title": "New Chat Markdown"
      },
      {
        "command": "filechat.configureApi",
        "title": "Configure Chat Markdown API Key"
      },
      {
        "command": "filechat.configureModel",
        "title": "Configure Chat Markdown Model"
      },
      {
        "command": "filechat.configureBaseUrl",
        "title": "Configure OpenAI-Compatible Base URL"
      },
      {
        "command": "filechat.refreshMcpTools",
        "title": "Refresh MCP Tools"
      }
    ],
    "configuration": {
      "title": "Chat Markdown",
      "properties": {
        "filechat.provider": {
          "type": "string",
          "enum": [
            "anthropic",
            "openai"
          ],
          "default": "anthropic",
          "description": "AI provider to use (anthropic or openai)",
          "scope": "application"
        },
        "filechat.model_name": {
          "type": "string",
          "description": "Model name to use with the selected provider (leave empty for default)",
          "scope": "application"
        },
        "filechat.base_url": {
          "type": "string",
          "description": "Base URL for OpenAI-compatible APIs (only used when provider is 'openai')",
          "scope": "application"
        },
        "filechat.apiKey": {
          "type": "string",
          "description": "API Key for the selected provider",
          "scope": "application"
        },
        "filechat.anthropicApiKey": {
          "type": "string",
          "description": "Anthropic API Key (legacy setting, use filechat.apiKey instead)",
          "scope": "application"
        },
        "filechat.mcpServers": {
          "type": "object",
          "description": "MCP server configurations for tool integration",
          "additionalProperties": {
            "type": "object",
            "properties": {
              "command": {
                "type": "string",
                "description": "Command to start the MCP server"
              },
              "args": {
                "type": "array",
                "items": {
                  "type": "string"
                },
                "description": "Arguments for the MCP server command"
              },
              "env": {
                "type": "object",
                "additionalProperties": {
                  "type": "string"
                },
                "description": "Environment variables for the MCP server"
              }
            },
            "required": [
              "command",
              "args"
            ]
          },
          "default": {},
          "scope": "application"
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "node ./esbuild.js --production",
    "esbuild-base": "node ./esbuild.js",
    "esbuild": "npm run esbuild-base -- --sourcemap",
    "esbuild-watch": "npm run esbuild-base -- --sourcemap --watch",
    "compile": "npm run esbuild",
    "watch": "npm run esbuild-watch",
    "pretest": "npm run esbuild && npm run lint",
    "lint": "eslint src --ext ts",
    "test": "node ./out/test/runTest.js",
    "build:vsix": "npm run vscode:prepublish && npx @vscode/vsce package"
  },
  "devDependencies": {
    "@types/glob": "^7.1.3",
    "@types/node": "^14.0.27",
    "@types/vscode": "^1.60.0",
    "@typescript-eslint/eslint-plugin": "^4.1.1",
    "@typescript-eslint/parser": "^4.1.1",
    "esbuild": "^0.25.2",
    "eslint": "^7.9.0",
    "glob": "^7.1.6",
    "typescript": "^4.0.2",
    "vscode-test": "^1.4.0"
  },
  "dependencies": {
    "@modelcontextprotocol/sdk": "^1.8.0",
    "zod": "^3.24.2"
  }
}
```
/Users/arusia/repos/filechat/src/extension.ts
```
import * as vscode from 'vscode';
import * as path from 'path';
import { DocumentListener } from './listener';
import { 
  getAnthropicApiKey, 
  setAnthropicApiKey, 
  getApiKey, 
  setApiKey, 
  getProvider, 
  setProvider,
  getModelName,
  setModelName,
  getBaseUrl,
  setBaseUrl
} from './config';
import { McpClientManager, McpServerConfig } from './mcpClient';

// Map to keep track of active document listeners
const documentListeners = new Map<string, vscode.Disposable>();

// Output channel for logging
export const outputChannel = vscode.window.createOutputChannel('FileChat');

// Create MCP client manager
export const mcpClientManager = new McpClientManager();

// Helper function for logging
export function log(message: string): void {
  outputChannel.appendLine(`[${new Date().toISOString()}] ${message}`);
  // Make sure the output channel is visible
  outputChannel.show(true);
}

/**
 * Activate the extension
 */
/**
 * Initialize MCP clients from configuration
 */
async function initializeMcpClients(): Promise<void> {
  try {
    const mcpServers = vscode.workspace.getConfiguration().get('filechat.mcpServers') as Record<string, McpServerConfig> || {};
    log(`Initializing ${Object.keys(mcpServers).length} MCP servers from configuration`);
    
    await mcpClientManager.initializeClients(mcpServers);
    log('MCP clients initialized successfully');
  } catch (error) {
    log(`Error initializing MCP clients: ${error}`);
    vscode.window.showErrorMessage(`Failed to initialize MCP servers: ${error}`);
  }
}

export function activate(context: vscode.ExtensionContext) {
  log('FileChat extension is now active');
  
  // Initialize MCP clients
  void initializeMcpClients();
  
  // Register for .chat.md files
  const selector: vscode.DocumentSelector = { pattern: '**/*.chat.md' };
  
  // Set up listeners for currently open chat files
  for (const document of vscode.workspace.textDocuments) {
    setupDocumentListener(document, context);
  }
  
  // Listen for newly opened documents
  context.subscriptions.push(
    vscode.workspace.onDidOpenTextDocument(document => {
      setupDocumentListener(document, context);
    })
  );
  
  // Listen for document closes to clean up listeners
  context.subscriptions.push(
    vscode.workspace.onDidCloseTextDocument(document => {
      const key = document.uri.toString();
      if (documentListeners.has(key)) {
        documentListeners.get(key)!.dispose();
        documentListeners.delete(key);
      }
    })
  );
  
  // Register commands
  context.subscriptions.push(
    vscode.commands.registerCommand('filechat.refreshMcpTools', async () => {
      await initializeMcpClients();
      vscode.window.showInformationMessage('MCP tools refreshed successfully');
    }),
    
    vscode.commands.registerCommand('filechat.newChat', async () => {
      // Create a new chat file
      const document = await vscode.workspace.openTextDocument({
        content: '# %% user\n',
        language: 'markdown'
      });
      
      await vscode.window.showTextDocument(document);
      
      // Save the file with .chat.md extension
      const defaultPath = path.join(
        vscode.workspace.workspaceFolders?.[0]?.uri.fsPath || '~',
        'new.chat.md'
      );
      
      const saveUri = await vscode.window.showSaveDialog({
        defaultUri: vscode.Uri.file(defaultPath),
        filters: { 'Chat Markdown': ['chat.md'] }
      });
      
      if (saveUri) {
        await vscode.workspace.fs.writeFile(saveUri, Buffer.from(document.getText()));
        const savedDoc = await vscode.workspace.openTextDocument(saveUri);
        await vscode.window.showTextDocument(savedDoc);
      }
    }),
    
    vscode.commands.registerCommand('filechat.configureApi', async () => {
      // Get current provider and key
      const currentProvider = getProvider();
      const currentKey = getApiKey() || (currentProvider === 'anthropic' ? getAnthropicApiKey() : undefined);
      
      // First, let user select the provider
      const providerOptions = ['anthropic', 'openai'];
      const selectedProvider = await vscode.window.showQuickPick(providerOptions, {
        placeHolder: 'Select AI provider',
        title: 'Configure Chat Markdown API',
        canPickMany: false,
        ignoreFocusOut: true
      });
      
      if (!selectedProvider) {
        return; // User cancelled
      }
      
      // Save provider setting
      await setProvider(selectedProvider);
      
      // Then get API key
      const message = currentKey 
        ? `Your ${selectedProvider} API key is configured. Enter a new key to update it.` 
        : `Enter your ${selectedProvider} API key:`;
      
      const apiKey = await vscode.window.showInputBox({
        prompt: message,
        password: true,
        value: currentKey
      });
      
      if (apiKey !== undefined) {  // Undefined means user cancelled
        await setApiKey(apiKey);
        
        // For backward compatibility, also set Anthropic key
        if (selectedProvider === 'anthropic') {
          await setAnthropicApiKey(apiKey);
        }
        
        vscode.window.showInformationMessage(
          apiKey ? `${selectedProvider} API key configured successfully` : `${selectedProvider} API key cleared`
        );
        
        // Listen for configuration changes
        context.subscriptions.push(
          vscode.workspace.onDidChangeConfiguration(e => {
            if (e.affectsConfiguration('filechat.mcpServers')) {
              initializeMcpClients();
            }
          })
        );
      }
      
      /**
       * Initialize MCP clients from configuration
       */
      async function initializeMcpClients(): Promise<void> {
        try {
          const mcpServers = vscode.workspace.getConfiguration().get('filechat.mcpServers') as Record<string, McpServerConfig> || {};
          log(`Initializing ${Object.keys(mcpServers).length} MCP servers from configuration`);
          
          await mcpClientManager.initializeClients(mcpServers);
          log('MCP clients initialized successfully');
        } catch (error) {
          log(`Error initializing MCP clients: ${error}`);
          vscode.window.showErrorMessage(`Failed to initialize MCP servers: ${error}`);
        }
      }
    }),
    
    vscode.commands.registerCommand('filechat.configureModel', async () => {
      // Get current provider and model
      const provider = getProvider();
      const currentModel = getModelName();
      
      // Show different default suggestions based on provider
      let modelSuggestions: string[] = [];
      if (provider === 'anthropic') {
        modelSuggestions = [
          'claude-3-opus-20240229',
          'claude-3-sonnet-20240229',
          'claude-3-haiku-20240307',
          'claude-3-5-sonnet-20240620',
          'claude-3-5-haiku-latest'
        ];
      } else if (provider === 'openai') {
        modelSuggestions = [
          'gpt-4-turbo',
          'gpt-4-vision-preview',
          'gpt-4-32k',
          'gpt-4',
          'gpt-3.5-turbo'
        ];
      }
      
      // Allow custom input or selection from list
      const selectedModel = await vscode.window.showQuickPick(
        ['Custom...', ...modelSuggestions],
        {
          placeHolder: `Select or enter a model for ${provider} (current: ${currentModel || 'default'})`,
          title: 'Configure Chat Markdown Model',
          ignoreFocusOut: true
        }
      );
      
      if (!selectedModel) {
        return; // User cancelled
      }
      
      let modelName = selectedModel;
      
      // If custom option selected, prompt for model name
      if (selectedModel === 'Custom...') {
        modelName = await vscode.window.showInputBox({
          prompt: `Enter model name for ${provider}:`,
          value: currentModel || '',
          ignoreFocusOut: true
        }) || '';
        
        if (!modelName) {
          return; // User cancelled
        }
      }
      
      // Save model setting
      await setModelName(modelName);
      vscode.window.showInformationMessage(`${provider} model set to: ${modelName}`);
    }),
    
    vscode.commands.registerCommand('filechat.configureBaseUrl', async () => {
      // This command only makes sense for OpenAI provider
      const provider = getProvider();
      if (provider !== 'openai') {
        vscode.window.showInformationMessage('Base URL is only used with OpenAI provider. Please switch provider to OpenAI first.');
        return;
      }
      
      const currentBaseUrl = getBaseUrl() || '';
      
      // Provide some examples of compatible APIs
      const baseUrlSuggestions = [
        { label: 'Default OpenAI API', detail: 'https://api.openai.com/v1' },
        { label: 'Azure OpenAI API', detail: 'https://YOUR_RESOURCE_NAME.openai.azure.com/openai/deployments/YOUR_DEPLOYMENT_NAME' },
        { label: 'Google Gemini API', detail: 'https://generativelanguage.googleapis.com/v1beta/openai' },
        { label: 'Custom...', detail: 'Enter a custom base URL' }
      ];
      
      const selectedOption = await vscode.window.showQuickPick(baseUrlSuggestions, {
        placeHolder: 'Select or enter base URL for OpenAI-compatible API',
        title: 'Configure OpenAI-Compatible Base URL',
        ignoreFocusOut: true
      });
      
      if (!selectedOption) {
        return; // User cancelled
      }
      
      let baseUrl = selectedOption.detail;
      
      // If custom option selected, prompt for base URL
      if (selectedOption.label === 'Custom...') {
        baseUrl = await vscode.window.showInputBox({
          prompt: 'Enter base URL for OpenAI-compatible API:',
          value: currentBaseUrl,
          ignoreFocusOut: true
        }) || '';
        
        if (!baseUrl) {
          return; // User cancelled
        }
      }
      
      // If user selected default OpenAI API, clear the setting
      if (selectedOption.label === 'Default OpenAI API') {
        await setBaseUrl('');
        vscode.window.showInformationMessage('Using default OpenAI API URL');
      } else {
        // Save base URL setting
        await setBaseUrl(baseUrl);
        vscode.window.showInformationMessage(`OpenAI-compatible base URL set to: ${baseUrl}`);
      }
    })
  );
}

/**
 * Sets up a document listener for a specific document
 */
function setupDocumentListener(document: vscode.TextDocument, context: vscode.ExtensionContext) {
  if (document.fileName.endsWith('.chat.md')) {
    const key = document.uri.toString();
    
    // Don't set up duplicates
    if (!documentListeners.has(key)) {
      // Make sure the document is shown in an editor
      // This helps ensure document edits can be applied
      vscode.window.showTextDocument(document, { preview: false })
        .then(() => {
          log(`Document shown in editor: ${document.fileName}`);
        }, (err: Error) => {
          log(`Error showing document: ${err}`);
        });
      
      const listener = new DocumentListener(document);
      const disposable = listener.startListening();
      documentListeners.set(key, disposable);
      
      // Add to context for cleanup
      context.subscriptions.push(disposable);
    }
  }
}

/**
 * Deactivate the extension
 */
export function deactivate() {
  // Clean up happens automatically through disposables
  documentListeners.forEach(disposable => {
    disposable.dispose();
  });
  documentListeners.clear();
}
```
/Users/arusia/repos/filechat/src/parser.ts
```
import { MessageParam, Content, Role } from './types';
import { log } from './extension';
import { isImageFile, resolveFilePath, readFileAsText, fileExists } from './utils/fileUtils';
import * as vscode from 'vscode';

/**
 * Parses a .chat.md file into structured messages
 * Returns a readonly array to prevent mutations
 * 
 * Note: Will exclude the last empty assistant block (used for triggering streaming)
 */
export function parseDocument(text: string, document?: vscode.TextDocument): readonly MessageParam[] {
  const messages: MessageParam[] = [];
  
  // Regex to split document on # %% markers - fixing the pattern to properly match all cases
  // We need to keep the original pattern that works, not the modified one that's causing issues
  const regex = /^# %% (user|assistant|tool_execute)\s*$/im;
  const blocks = text.split(regex);
  
  // Debug logging
  log(`Split document into ${blocks.length} blocks`);
  for (let i = 0; i < Math.min(blocks.length, 10); i++) {
    log(`Block ${i}: "${blocks[i].substring(0, 20).replace(/\n/g, '\\n')}${blocks[i].length > 20 ? '...' : ''}"`);
  }
  
  // Skip first empty element if exists
  let startIdx = blocks[0].trim() === '' ? 1 : 0;
  
  // Check if the last block is an empty assistant block
  const hasEmptyLastAssistant = 
    blocks.length >= startIdx + 2 && 
    blocks[blocks.length - 2].toLowerCase().trim() === 'assistant' && 
    blocks[blocks.length - 1].trim() === '';
  
  // Determine endpoint for parsing (exclude empty last assistant block)
  const endIdx = hasEmptyLastAssistant ? blocks.length - 2 : blocks.length;
  
  for (let i = startIdx; i < endIdx; i += 2) {
    // If we have a role but no content block, skip
    if (i + 1 >= endIdx) {
      break;
    }
    
    const role = blocks[i].toLowerCase().trim();
    const content = blocks[i + 1].trim();
    
    // Skip empty assistant blocks entirely (they're just triggers)
    if (role === 'assistant' && content === '') {
      continue;
    }
    
    // Detect if this is a tool_execute block
    if (role === 'tool_execute') {
      // Tool execute blocks are treated as user messages
      if (content) {
        messages.push({
          role: 'user',
          content: [{ type: 'text', value: content }]
        });
      }
      // Skip this block in normal processing
      continue;
    }
    
    if (role === 'user' as Role) {
      // Only add user message if it has actual content
      const parsedContent = parseUserContent(content, document);
      if (parsedContent.length > 0) {
        messages.push({
          role,
          content: parsedContent
        });
      }
    } else if (role === 'assistant') {
      messages.push({
        role,
        content: [{ type: 'text', value: content }]
      });
    }
  }
  
  return Object.freeze(messages);
}

/**
 * Parses user content to extract text and file references
 */
function parseUserContent(text: string, document?: vscode.TextDocument): Content[] {
  const content: Content[] = [];
  
  // Original format: "Attached file at /path/to/file"
  const fileAttachmentRegex = /^Attached file at ([^\n]+)\n(?:```[^\n]*\n([\s\S]*?)```|\[image content\])/gm;
  
  // New format: Markdown-style links like [anything](test.py)
  const markdownLinkRegex = /\[([^\]]*)\]\(([^)]+)\)/g;
  
  // Collection of file attachments to add at the top
  const topAttachments: string[] = [];
  
  // Process markdown-style links and collect attachments for top
  if (document) {
    let mdMatch;
    
    // First pass - collect all matches and create attachments
    while ((mdMatch = markdownLinkRegex.exec(text)) !== null) {
      const altText = mdMatch[1];
      const filePath = mdMatch[2];
      
      // Skip links that are explicitly marked to not be treated as files
      // by checking if the alt text contains "nofile" or "no-file"
      if (altText.toLowerCase().includes('nofile') || 
          altText.toLowerCase().includes('no-file')) {
        continue;
      }
      
      const resolvedPath = resolveFilePath(filePath, document);
      const isImage = isImageFile(filePath);
      
      // For text files, read the content
      let fileContent;
      if (!isImage && fileExists(resolvedPath)) {
        fileContent = readFileAsText(resolvedPath);
      }
      
      // Create attachment format but don't replace the link
      const attachment = isImage 
        ? `Attached file at ${filePath}\n[image content]\n\n`
        : `Attached file at ${filePath}\n\`\`\`\n${fileContent || 'Unable to read file content'}\n\`\`\`\n\n`;
      
      topAttachments.push(attachment);
      
      log(`Added attachment for: ${filePath} (${isImage ? 'image' : 'text'})`);
    }
  }
  
  // Add all attachments at the top of the text
  if (topAttachments.length > 0) {
    text = topAttachments.join('') + text;
    log(`Added ${topAttachments.length} attachments at the top of the message`);
  }
  
  let lastIndex = 0;
  let match;
  
  // Process the original "Attached file at" format (which now includes the ones we added at the top)
  while ((match = fileAttachmentRegex.exec(text)) !== null) {
    // Add text before the attachment
    const beforeText = text.substring(lastIndex, match.index).trim();
    if (beforeText) {
      content.push({ type: 'text', value: beforeText });
    }
    
    const path = match[1];
    if (path.endsWith('.png') || path.endsWith('.jpg') || path.endsWith('.jpeg') || 
        path.endsWith('.gif') || path.endsWith('.webp')) {
      content.push({ type: 'image', path });
    } else {
      // For non-image files, extract content from code block
      content.push({ type: 'text', value: match[2] || '' });
    }
    
    lastIndex = match.index + match[0].length;
  }
  
  
  // Add remaining text
  const remainingText = text.substring(lastIndex).trim();
  if (remainingText) {
    content.push({ type: 'text', value: remainingText });
  }
  
  // If no content was extracted, use the full text
  if (content.length === 0 && text.trim()) {
    content.push({ type: 'text', value: text });
  }
  
  return content;
}

/**
 * Checks if a document ends with an empty assistant block
 * Used to determine when to start streaming
 */
export function hasEmptyAssistantBlock(text: string): boolean {
  // Log the exact document text for debugging (truncated)
  const displayText = text.length > 100 ? text.substring(text.length - 100) : text;
  log(`Checking for empty assistant block in: "${displayText.replace(/\n/g, '\\n')}"`);
  
  // Check if the document ends with a pattern that should trigger streaming
  // Specifically, we want "# %% assistant" followed by a newline and optional whitespace at the end
  const lastAssistantIndex = text.lastIndexOf('# %% assistant');
  
  // If no assistant block found or it's not near the end, return false
  if (lastAssistantIndex === -1 || lastAssistantIndex < text.length - 30) {
    log('No assistant block found near the end of the document');
    return false;
  }
  
  // Check if there's a newline after "# %% assistant"
  const textAfterMarker = text.substring(lastAssistantIndex + 14); // Length of '# %% assistant'
  
  // First, check for at least one newline
  if (!textAfterMarker.includes('\n')) {
    log('No newline after "# %% assistant", not triggering streaming');
    return false;
  }
  
  // Now check if there's only whitespace after the newline
  const hasContentAfterNewline = /\n\s*[^\s]/.test(textAfterMarker);
  
  if (hasContentAfterNewline) {
    log('Found content after newline, not an empty assistant block');
    return false;
  }
  
  // If we got here, we have "# %% assistant" followed by a newline and only whitespace after that
  log('Found empty assistant block with newline, triggering streaming');
  return true;
}

/**
 * Checks if a document has an empty tool_execute block
 * Used to determine when to execute a tool
 */
export function hasEmptyToolExecuteBlock(text: string): boolean {
  // Log document suffix for debugging
  const displayText = text.length > 100 ? text.substring(text.length - 100) : text;
  log(`Checking for empty tool_execute block in: "${displayText.replace(/\n/g, '\\n')}"`);

  // More precise approach: find all tool_execute blocks and check if any are empty
  // Look for blocks that are either at the end of the document or followed by another block
  const blockMatches = [];
  const regex = /# %% tool_execute\s*([\s\S]*?)(?=\n# %%|$)/gm;
  let match;
  
  while ((match = regex.exec(text)) !== null) {
    const blockContent = match[1].trim();
    const position = match.index;
    blockMatches.push({ position, content: blockContent });
    
    log(`Found tool_execute block at ${position}: content=${blockContent ? 'non-empty' : 'empty'}`);
  }
  
  // Check if we found any empty blocks
  const emptyBlocks = blockMatches.filter(block => block.content === '');
  
  if (emptyBlocks.length > 0) {
    log(`Found ${emptyBlocks.length} empty tool_execute block(s), will trigger tool execution`);
    return true;
  }
  
  return false;
}

/**
 * Gets all assistant block positions in a document
 * Used to find where to place streamed content
 */
export function findAssistantBlocks(text: string): {start: number, end: number}[] {
  const blocks: {start: number, end: number}[] = [];
  const regex = /^# %% assistant\s*$/im;
  
  let match;
  const lines = text.split('\n');
  
  for (let i = 0; i < lines.length; i++) {
    if (regex.test(lines[i])) {
      // Found an assistant block
      const start = lines.slice(0, i).join('\n').length + (i > 0 ? 1 : 0); // Add newline except for first line
      const end = start + lines[i].length;
      blocks.push({start, end});
    }
  }
  
  return blocks;
}

/**
 * Finds all assistant blocks with their content start positions
 * Used for more precise token insertion
 */
export function findAllAssistantBlocks(text: string): {markerStart: number, contentStart: number}[] {
  const blocks: {markerStart: number, contentStart: number}[] = [];
  const lines = text.split('\n');
  let lineOffset = 0;
  
  for (let i = 0; i < lines.length; i++) {
    if (/^# %% assistant\s*$/i.test(lines[i])) {
      // Found an assistant block
      const markerStart = lineOffset;
      
      // Calculate the content start (after the marker line)
      let contentStart = lineOffset + lines[i].length;
      
      // Skip any whitespace after the marker
      while (contentStart < text.length && 
             (text[contentStart] === ' ' || text[contentStart] === '\t')) {
        contentStart++;
      }
      
      // Skip newline if present
      if (contentStart < text.length && text[contentStart] === '\n') {
        contentStart++;
      }
      
      blocks.push({markerStart, contentStart});
    }
    
    lineOffset += lines[i].length + 1; // +1 for the newline
  }
  
  return blocks;
}
```
---


---



- Additional important note: as soon as you encounter "The user has chosen to disallow the tool call.", immediately stop doing everything and ask user for the reason.

Initialize call done.
    